{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit, train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import pandas as pd\n",
    "import data \n",
    "from collections import Counter\n",
    "\n",
    "# plt.style.use('dark_background')\n",
    "# sns.set(style=\"white\")\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "NUM_PATIENTS = 12044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:01<00:00, 35.87it/s]\n",
      "48it [00:03, 14.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final shape (12044, 433)\n"
     ]
    }
   ],
   "source": [
    "features = data.get_features() # uses several forms\n",
    "outcomes = data.get_outcomes() # 2 outcomes: iai, and iai_intervention\n",
    "df = pd.merge(features, outcomes, on='id', how='left')\n",
    "X_feats_full = data.preprocess(features)\n",
    "\n",
    "# remove unusable features\n",
    "ks = [k for k in X_feats_full.keys() if not k in ['id'] and not 'IAI' in k]\n",
    "X_feats_full= X_feats_full[ks]\n",
    "\n",
    "# get actual features\n",
    "X_np = X_feats_full.values\n",
    "feature_names = list(X_feats_full)\n",
    "y_np = outcomes['iai_intervention']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful = ['VomitWretch_1', 'RecodedMOI_1', 'GCSScore_1', 'ThoracicTender_1', 'ThoracicTrauma_1', \n",
    "          'Costal_1', 'DecrBreathSound_1', 'AbdDistention_1', 'AbdomenPain_1', 'AbdTenderDegree_1',\n",
    "          'AbdTrauma_1', 'SeatBeltSign_1', 'DistractingPain_1']\n",
    "# InjuryMechanism_1, hypotension?, femure fracture\n",
    "ks = set()\n",
    "for k_useful in useful:\n",
    "    for k in feature_names:\n",
    "        if k_useful in k:\n",
    "            ks.add(k)\n",
    "ks = np.array(list(ks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feats = X_feats_full[ks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12044, 53)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_feats.values, y_np, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 9463, 1: 172})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision tree fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type='tree'\n",
    "max_depth = 3\n",
    "num_cv = 10\n",
    "\n",
    "if model_type == 'tree':\n",
    "    m = DecisionTreeClassifier(max_depth=max_depth, class_weight={0: 1, 1: 500})\n",
    "elif model_type == 'logistic':\n",
    "    m = LogisticRegressionCV(class_weight={0: 1, 1: 300}, cv=3, max_iter=100)\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n",
    "m_cv = cross_validate(m, X_train, y_train, cv=num_cv, scoring=['precision', 'recall', 'f1', 'balanced_accuracy', 'roc_auc'],\n",
    "                      return_train_score=True, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\tprecision\n",
      "0.98\trecall\n",
      "0.05\tf1\n",
      "0.65\tbalanced_accuracy\n",
      "0.82\troc_auc\n"
     ]
    }
   ],
   "source": [
    "# print('metric\\ttrain\\ttest')\n",
    "for key in m_cv:\n",
    "    if 'test' in key:\n",
    "#         print(f\"{key.replace('test_', '')}\\t{np.mean(m_cv[key.replace('test', 'train')]):0.2f}\\t{np.mean(m_cv[key]):0.2f}\")\n",
    "        print(f\"{np.mean(m_cv[key]):0.2f}\\t{key.replace('test_', '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AbdomenPain_1_2', 10),\n",
       " ('RecodedMOI_1_2', 10),\n",
       " ('GCSScore_1', 10),\n",
       " ('AbdTrauma_1_2', 10),\n",
       " ('DecrBreathSound_1_4', 9),\n",
       " ('DistractingPain_1_1', 8),\n",
       " ('DistractingPain_1_2', 2),\n",
       " ('RecodedMOI_1_4', 1),\n",
       " ('AbdTenderDegree_1_1.0', 1),\n",
       " ('RecodedMOI_1_1', 1)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_common_feats(m_cv, model_type='tree'):\n",
    "    if model_type == 'tree':\n",
    "        feats_used = []\n",
    "        for i in range(len(m_cv['estimator'])):\n",
    "            m_fit = m_cv['estimator'][i]\n",
    "            feats_used += list(ks[m_fit.feature_importances_ != 0])\n",
    "    elif model_type == 'logistic':\n",
    "        feats_used = []\n",
    "        for i in range(len(m_cv['estimator'])):\n",
    "            m_fit = m_cv['estimator'][i]\n",
    "            num_feats = 5\n",
    "            # get top num_feats features with biggest bsolute weights\n",
    "            idxs = np.abs(m_fit.coef_).flatten().argsort()[-num_feats:][::-1]\n",
    "            feats_used += list(ks[idxs])\n",
    "    return sorted(dict(Counter(feats_used)).items(), key=lambda kv: kv[1], reverse=True)\n",
    "        \n",
    "count_common_feats(m_cv, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a tree\n",
    "m_fit = m_cv['estimator'][0]\n",
    "plt.figure(dpi=300)\n",
    "plot_tree(m_fit, feature_names=ks)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
