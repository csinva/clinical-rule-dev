{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import data_pecarn\n",
    "import data_psrc\n",
    "import data\n",
    "import train\n",
    "import matplotlib.gridspec as grd\n",
    "from data import feats_numerical, feats_categorical, meta\n",
    "\n",
    "# sns.set(style=\"black\")\n",
    "# plt.style.use('dark_background')\n",
    "outcome_def = 'iai_intervention' # output\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing pecarn preprocessing...\n",
      "computing psrc preprocessing...\n"
     ]
    }
   ],
   "source": [
    "df_pecarn, df_psrc, common_feats, filtered_feats_pecarn, filtered_feats_psrc = data.load_it_all(dummy=True)\n",
    "df = df_pecarn[common_feats].append(df_psrc[common_feats])\n",
    "processed_feats = data.select_final_feats(common_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_idxs = data.pecarn_train_idxs\n",
    "test_idxs1 = data.pecarn_test_idxs\n",
    "test_idxs2 = data.psrc_train_idxs + data.psrc_test_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 ['VomitWretch_unknown', 'AbdDistention_yes', 'MOI_Motor vehicle collision', 'InitHeartRate', 'AbdTrauma_or_SeatBeltSign_yes', 'MOI_Object struck abdomen', 'AbdTenderDegree_Severe', 'RtCostalTender', 'MOI_Bike collision/fall', 'AbdomenPain_yes', 'ThoracicTrauma_yes', 'AbdTenderDegree_Mild', 'Hypotension_yes', 'VomitWretch_yes', 'MOI_Pedestrian/bicyclist struck by moving vehicle', 'InitSysBPRange', 'MOI_Fall from an elevation', 'LtCostalTender', 'AbdTenderDegree_Moderate', 'MOI_Motorcycle/ATV/Scooter collision', 'Age', 'MOI_unknown', 'DecrBreathSound_yes', 'GCSScore_Full_yes', 'AbdDistention_unknown', 'CostalTender']\n"
     ]
    }
   ],
   "source": [
    "print(len(processed_feats), processed_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5] [6] [8, 9, 10, 11, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "print(train_idxs, test_idxs1, test_idxs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = f'results/jun17_0'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "for balancing in ['ros', 'smote']:\n",
    "    for balancing_ratio in [100, 5]: \n",
    "        for model_type in ['logistic', 'dt']: #, 'rf', 'mlp2', 'svm']): # 'rf', 'mlp2', 'svm', 'gb'\n",
    "            for feature_selection in ['select_stab_lasso', 'select_lasso', 'select_rf']: # select_lasso, select_rf, None\n",
    "                for feature_selection_num in tqdm([5, 10, len(processed_feats)]):\n",
    "                    out_name = f'{model_type}_{feature_selection}={feature_selection_num}_{balancing}={balancing_ratio}'\n",
    "                    train.train(df,\n",
    "                                feat_names=processed_feats,\n",
    "                                model_type=model_type, \n",
    "                                balancing=balancing,\n",
    "                                outcome_def=outcome_def,\n",
    "                                balancing_ratio=balancing_ratio,\n",
    "                                out_name=f'{out_dir}/{out_name}.pkl',\n",
    "                                feature_selection=feature_selection,\n",
    "                                feature_selection_num=feature_selection_num,\n",
    "                                train_idxs=train_idxs,\n",
    "                                test_idxs1=test_idxs1,\n",
    "                                test_idxs2=test_idxs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "from stability_selection import StabilitySelection\n",
    "\n",
    "\n",
    "def _generate_dummy_classification_data(p=1000, n=1000, k=5, random_state=123321):\n",
    "\n",
    "    rng = check_random_state(random_state)\n",
    "\n",
    "    X = rng.normal(loc=0.0, scale=1.0, size=(n, p))\n",
    "    betas = np.zeros(p)\n",
    "    important_betas = np.sort(rng.choice(a=np.arange(p), size=k))\n",
    "    betas[important_betas] = rng.uniform(size=k)\n",
    "\n",
    "    probs = 1 / (1 + np.exp(-1 * np.matmul(X, betas)))\n",
    "    y = (probs > 0.5).astype(int)\n",
    "\n",
    "    return X, y, important_betas\n",
    "\n",
    "## This is all preparation of the dummy data set\n",
    "n, p, k = 500, 1000, 5\n",
    "\n",
    "X, y, important_betas = _generate_dummy_classification_data(n=n, k=k)\n",
    "base_estimator = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "\n",
    "## Here stability selection is instantiated and run\n",
    "selector = StabilitySelection(base_estimator=base_estimator, lambda_name='C',\n",
    "                              lambda_grid=np.logspace(-5, -1, 5), threshold=1e-999).fit(X, y)\n",
    "\n",
    "print(selector.get_support(indices=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.stability_scores_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
