{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import data\n",
    "import sys\n",
    "files_dict = data.load_files_dict_single_site()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site = 'Atlanta'\n",
    "# site = 'Columbus'\n",
    "site = 'WashingtonDC'\n",
    "df = files_dict[site]\n",
    "qs, responses_df, themes_df = data.split_single_site_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbered_list(responses):\n",
    "    return '\\n'.join([f'{i+1}. {c.strip()}' for i, c in enumerate(responses)])\n",
    "\n",
    "\n",
    "themes_prompt = '''### You are given a question and a set of responses below.\n",
    "\n",
    "**Question**: {question}\n",
    "\n",
    "**Responses**:\n",
    "{response_list}\n",
    "\n",
    "### Group all responses into 2 or more non-overlapping themes.\n",
    "### Return a comma-separated list, where each element is a theme, followed by the numbers of the responses that fall into that theme in brackets.\n",
    "### **Example answer**: Theme 1: Negative responses [1, 2, 5], Theme 2: Positive responses [3, 4]\n",
    "\n",
    "**Answer**: Theme 1:'''\n",
    "\n",
    "llm = imodelsx.llm.get_llm('gpt-4', repeat_delay=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run single example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question, responses, theme_dict = data.get_data_for_question_single_site(\n",
    "#     question_num=2, qs=qs, responses_df=responses_df, themes_df=themes_df)\n",
    "\n",
    "# resps = responses[pd.notna(responses)]\n",
    "# prompt = themes_prompt.format(\n",
    "#     question=question,\n",
    "#     response_list=numbered_list(resps)\n",
    "# )\n",
    "# print(prompt)\n",
    "# llm(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Screen valid questions\n",
    "Valid questions have multiple unique responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique(resps):\n",
    "    resps_match = resps.apply(str.lower)\n",
    "    resps_match = resps_match.str.replace('[^\\w\\s]', '')\n",
    "    # print(set(resps_match))\n",
    "    return len(set(resps_match))\n",
    "\n",
    "\n",
    "# screen valid questions\n",
    "def get_valid_question_nums(qs, responses_df, themes_df):\n",
    "    valid_question_nums = []\n",
    "    for question_num in tqdm(range(len(qs)), position=0):\n",
    "\n",
    "        question, responses, theme_dict = data.get_data_for_question_single_site(\n",
    "            question_num=question_num, qs=qs, responses_df=responses_df, themes_df=themes_df)\n",
    "        resps = responses[pd.notna(responses)]\n",
    "\n",
    "        # valid only if there are multiple unique responses\n",
    "        if count_unique(resps) > 3:\n",
    "            # print(resps)\n",
    "            valid_question_nums.append(question_num)\n",
    "    return valid_question_nums\n",
    "\n",
    "\n",
    "valid_question_nums = get_valid_question_nums(qs, responses_df, themes_df)\n",
    "print('num valid qs', len(valid_question_nums), 'of', len(qs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run generating themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_themes_and_resps(valid_question_nums, qs, responses_df, themes_df):\n",
    "    themes_generated = {}\n",
    "    resps_list = {}\n",
    "    for question_num in tqdm(valid_question_nums, position=0):\n",
    "\n",
    "        question, responses, theme_dict = data.get_data_for_question_single_site(\n",
    "            question_num=question_num, qs=qs, responses_df=responses_df, themes_df=themes_df)\n",
    "        resps = responses[pd.notna(responses)]\n",
    "\n",
    "        prompt = themes_prompt.format(\n",
    "            question=question,\n",
    "            response_list=numbered_list(resps)\n",
    "        )\n",
    "        ans = llm(prompt)\n",
    "        themes_generated[question_num] = [s.strip(' ,:1234567890')\n",
    "                                          for s in ans.split('Theme')]\n",
    "        resps.index = np.arange(len(resps)) + 1\n",
    "        resps_list[question_num] = resps\n",
    "    return themes_generated, resps_list\n",
    "\n",
    "\n",
    "themes_generated, resps_list = get_themes_and_resps(\n",
    "    valid_question_nums, qs, responses_df, themes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dprint(*args, f):\n",
    "    # print(*args, file=sys.stdout)\n",
    "    print(*args, file=f)\n",
    "\n",
    "\n",
    "with open(f'../figs/themes/themes_generated_{site}.md', 'w') as f:\n",
    "    for question_num in valid_question_nums:\n",
    "        dprint('### Question:', qs[question_num], f=f)\n",
    "        dprint('\\nResponses', f=f)\n",
    "        for i in range(len(resps_list[question_num])):\n",
    "            dprint(f'{i+1}. {resps_list[question_num].iloc[i]}', f=f)\n",
    "        dprint('\\nThemes', f=f)\n",
    "        # print(themes_generated[question_num])\n",
    "        themes = themes_generated[question_num]\n",
    "        for i, theme in enumerate(themes):\n",
    "            dprint(f'- Theme {i + 1}:', theme, f=f)\n",
    "        dprint('', f=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate human experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SITES = ['Atlanta', 'Columbus', 'WashingtonDC']\n",
    "vset = None\n",
    "for site in SITES:\n",
    "    df = files_dict[site]\n",
    "    qs, responses_df, themes_df = data.split_single_site_df(df)\n",
    "    valid_question_nums = get_valid_question_nums(qs, responses_df, themes_df)\n",
    "    if vset is None:\n",
    "        vset = set(valid_question_nums)\n",
    "    else:\n",
    "        vset = vset.intersection(valid_question_nums)\n",
    "questions_selected = list(vset)\n",
    "pd.Series(questions_selected).to_csv(\n",
    "    '../figs/human/themes_questions_selected.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_brackets(s):\n",
    "    return s.split('[')[0].strip()\n",
    "\n",
    "\n",
    "MAX_THEMES = 5\n",
    "ddf = defaultdict(list)\n",
    "for i, q in enumerate(questions_selected):\n",
    "    site = SITES[i % len(SITES)]\n",
    "\n",
    "    df = files_dict[site]\n",
    "    qs, responses_df, themes_df = data.split_single_site_df(df)\n",
    "    themes_generated, resps_list = get_themes_and_resps(\n",
    "        vset, qs, responses_df, themes_df)\n",
    "    ts = [remove_brackets(s) for s in themes_generated[q]]\n",
    "    resps = resps_list[q]\n",
    "    n_resps = len(resps)\n",
    "    for resp in resps:\n",
    "        ddf['responses'].append(resp)\n",
    "        ddf['site'].append(site)\n",
    "        ddf['question'].append(qs[q])\n",
    "\n",
    "        # Themes without citations\n",
    "        for i in range(len(ts)):\n",
    "            ddf[f'Theme {i+1}'].append(ts[i])\n",
    "        for i in range(len(ts), MAX_THEMES + 1):\n",
    "            ddf[f'Theme {i+1}'].append('')\n",
    "        ddf['themes'].append(ts)\n",
    "\n",
    "    # answers (map citations to answers)\n",
    "    ans_vec = np.zeros((n_resps, MAX_THEMES))\n",
    "    for i, t in enumerate(themes_generated[q]):\n",
    "        try:\n",
    "            nums = t.split('[')[1].split(']')[0].split(',')\n",
    "        except:\n",
    "            print(t)\n",
    "        nums = np.array([int(n.strip()) for n in nums]) - 1\n",
    "        ans_vec[nums, i] = 1\n",
    "    for i in range(MAX_THEMES):\n",
    "        ddf[f'ans {i+1}'] += ans_vec[:, i].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = pd.DataFrame(ddf)\n",
    "dx.to_csv('../figs/human/themes_template.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hum1 0.862 0.0252\n",
      "hum2 0.867 0.0248\n",
      "hum3 0.878 0.024\n"
     ]
    }
   ],
   "source": [
    "template = pd.read_csv('../figs/human/themes_template.csv')\n",
    "\n",
    "annots = {\n",
    "    'hum1': 'human1',\n",
    "    'hum2': 'human2',\n",
    "    'hum3': 'human3',\n",
    "}\n",
    "\n",
    "for k, v in annots.items():\n",
    "    hum = pd.read_csv(f'../figs/human/collected/themes_{v}.csv', skiprows=1)\n",
    "\n",
    "    # check for matching index\n",
    "    def remove_all_whitespace(s):\n",
    "        return ''.join(s.split())\n",
    "\n",
    "    assert np.all(hum['response'].apply(remove_all_whitespace).values ==\n",
    "                  template['responses'].apply(remove_all_whitespace).values)\n",
    "\n",
    "    # load answer\n",
    "    def get_clean_annotation(s):\n",
    "        return s.split(',')[-1].strip()\n",
    "\n",
    "    template[k] = hum['annotation'].astype(str).apply(\n",
    "        get_clean_annotation).values.astype(float).astype(int)\n",
    "    # check that values are in range 1-5\n",
    "    assert np.all(template[k].values >= 1), np.unique(template[k])\n",
    "    assert np.all(template[k].values <= 5)\n",
    "    ans = template[['ans 1', 'ans 2', 'ans 3', 'ans 4', 'ans 5']].values\n",
    "\n",
    "    # compute mean\n",
    "    template[f'{k}_correct'] = False\n",
    "    for i in range(len(template)):\n",
    "        if ans[i, template[k][i] - 1] == 1:\n",
    "            template.at[i, f'{k}_correct'] = True\n",
    "    print(k, template[f'{k}_correct'].mean().round(\n",
    "        3), template[f'{k}_correct'].sem().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inter-annotator agreement 0.867 0.0143\n"
     ]
    }
   ],
   "source": [
    "# def agreement(k1, k2):\n",
    "#     return np.mean(template[k1] == template[k2])\n",
    "# agreements = [agreement('hum1', 'hum2'), agreement(\n",
    "#     'hum1', 'hum3'), agreement('hum2', 'hum3')]\n",
    "x = np.concatenate([template['hum1'], template['hum2'], template['hum3']])\n",
    "y = np.concatenate([template['hum2'], template['hum3'], template['hum1']])\n",
    "print('inter-annotator agreement', np.mean(x == y).round(3),\n",
    "      (np.std(x == y) / np.sqrt(len(x))).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg num classes 3.2393617021276597 random acc 0.30870279146141216\n"
     ]
    }
   ],
   "source": [
    "themes = template[['Theme 1', 'Theme 2', 'Theme 3', 'Theme 4', 'Theme 5']]\n",
    "num_non_nan_themes = (~themes.isna()).sum(axis=1)\n",
    "print('avg num classes', num_non_nan_themes.mean(),\n",
    "      'random acc', 1 / num_non_nan_themes.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
