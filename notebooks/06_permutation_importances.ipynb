{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit interpretable models to the training set and test on validation sets. Uses imodels package as of 10/25/2020 (v0.2.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import viz\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join as oj\n",
    "import os\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from dtreeviz.trees import *\n",
    "import imodels\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.inspection import permutation_importance\n",
    "import data\n",
    "from pecarn_predict import pecarn_rule_predict\n",
    "import validate\n",
    "outcome_def = 'iai_intervention' # output\n",
    "MODELS_DIR = '../models/simple_3_splits'\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# load the data\n",
    "df_pecarn, df_psrc, common_feats, filtered_feats_pecarn, filtered_feats_psrc = data.load_it_all(dummy=True)\n",
    "df = df_pecarn[common_feats].append(df_psrc[common_feats])\n",
    "processed_feats = data.select_final_feats(common_feats)\n",
    "\n",
    "# split the idxs\n",
    "train_idxs = df.cv_fold.isin(data.pecarn_train_idxs)\n",
    "test_idxs1 = df.cv_fold.isin(data.pecarn_test_idxs)\n",
    "test_idxs2 = df.cv_fold.isin(data.psrc_train_idxs + data.psrc_test_idxs)\n",
    "\n",
    "# split the data\n",
    "X, y = df[processed_feats], df[outcome_def]\n",
    "half = train_idxs.sum() // 2\n",
    "split_to_plot = '_test2'\n",
    "\n",
    "# 3-split\n",
    "X_train, y_train = X[train_idxs], y[train_idxs]\n",
    "X_cv, y_cv = X_train, y_train\n",
    "X_test1, y_test1 = X[test_idxs1], y[test_idxs1]\n",
    "\n",
    "# try loading psrc data\n",
    "if df_psrc.shape[0] > 0:\n",
    "    X_test2, y_test2 = X[test_idxs2], y[test_idxs2]\n",
    "else:\n",
    "    X_test2, y_test2 = X_test1, y_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at importances for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 29.97it/s]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    imp_dict = pkl.load(open('../reports/importances.pkl', 'rb'))\n",
    "    importances = imp_dict['importances']\n",
    "    fnames = imp_dict['fnames']\n",
    "except:\n",
    "    suffix = '_train'\n",
    "    fnames = []\n",
    "    importances = []\n",
    "    for fname in tqdm(sorted(os.listdir(MODELS_DIR))):\n",
    "        if 'pkl' in fname:\n",
    "            if not fname[:-4] == 'rf': # and not 'grl' in fname: # and not 'irf' in fname:\n",
    "                fnames.append(fname[:-4])\n",
    "                r = pkl.load(open(oj(MODELS_DIR, fname), 'rb'))\n",
    "                threshes = np.array(r['threshes' + suffix])\n",
    "\n",
    "                sens = np.array(r['sens' + suffix])\n",
    "                spec = np.array(r['spec' + suffix])\n",
    "                best_idx = np.argmax(5 * sens + spec)\n",
    "                m = r['model']\n",
    "                print(m)\n",
    "\n",
    "                importances.append(\n",
    "                    permutation_importance(m, X_train, y_train,\n",
    "                                           n_repeats=1,\n",
    "                                           scoring='roc_auc',\n",
    "                                           random_state=0).importances_mean\n",
    "                )\n",
    "    pkl.dump({'importances': importances, 'fnames': fnames}, open('../reports/importances.pkl', 'wb'))            \n",
    "    imp_dict = pkl.load(open('../reports/importances.pkl', 'rb'))\n",
    "    importances = imp_dict['importances']\n",
    "    fnames = imp_dict['fnames']\n",
    "    \n",
    "# pecarn importances\n",
    "def m(d):\n",
    "    low_risk_patients, missed_patients, stats = pecarn_rule_predict(d, print_rule=False)\n",
    "    return stats['roc_auc']\n",
    "\n",
    "np.random.seed(0)\n",
    "imps = []\n",
    "rocs = []\n",
    "df_pecarn, df_psrc, common_feats, filtered_feats_pecarn, filtered_feats_psrc = data.load_it_all(dummy=False)\n",
    "final_feats = data.select_final_feats(common_feats)\n",
    "final_feats = [feat.replace('GCSScore_Full', 'GCSScore') for feat in final_feats]\n",
    "for feat in tqdm(final_feats):\n",
    "    d = deepcopy(df_pecarn)\n",
    "    d[feat] = np.random.permutation(d[feat])\n",
    "    rocs.append(m(d))\n",
    "#     print(feat, rocs[-1])\n",
    "rocs = m(df_pecarn) - np.array(rocs)    \n",
    "reorder = np.array([1, 2, 4, 6, 7, 8, 10, 11, 12, 12, 12, 12, 12, 12, 14, 15])\n",
    "# for i in range(len(final_feats)):\n",
    "#     print(i, np.array(final_feats)[reorder][i], rocs[reorder][i])\n",
    "importances = importances + [rocs[reorder]]\n",
    "fnames += ['PECARN']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude irf / grl\n",
    "IDXS_EXCLUDE = [2, 3]\n",
    "imps = [importances[i] for i in range(len(importances))\n",
    "        if not i in IDXS_EXCLUDE]\n",
    "# print(imps)\n",
    "fnames = [fnames[i] for i in range(len(fnames))\n",
    "      if not i in IDXS_EXCLUDE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AbdTenderDegree_None': 4,\n",
       " 'AbdTrauma_or_SeatBeltSign_yes': 4,\n",
       " 'GCSScore_Full_yes': 4,\n",
       " 'DecrBreathSound_yes': 3,\n",
       " 'ThoracicTrauma_yes': 3,\n",
       " 'VomitWretch_yes': 3,\n",
       " 'Hypotension_yes': 2,\n",
       " 'CostalTender_yes': 1,\n",
       " 'MOI_Bike collision/fall': 1,\n",
       " 'MOI_Motor vehicle collision': 1,\n",
       " 'MOI_Motorcycle/ATV/Scooter collision': 1,\n",
       " 'MOI_Object struck abdomen': 1,\n",
       " 'MOI_Pedestrian/bicyclist struck by moving vehicle': 1,\n",
       " 'AbdDistention_or_AbdomenPain_yes': 0,\n",
       " 'Age<2_yes': 0,\n",
       " 'MOI_Fall from an elevation': 0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks = list(X.keys())\n",
    "feat_counts = {k: 0 for k in X.keys()}\n",
    "feat_sums = {k: 0 for k in X.keys()}\n",
    "feat_lists = {k: [] for k in X.keys()}\n",
    "for i in range(len(imps)):\n",
    "    for j in range(len(feat_counts)):\n",
    "        if not imps[i][j] <= 0:\n",
    "            feat_counts[ks[j]] += 1\n",
    "            feat_sums[ks[j]] += imps[i][j]\n",
    "            feat_lists[ks[j]] += [fnames[i]]\n",
    "def sort_by_val(x):\n",
    "    return {k: v for k, v in sorted(x.items(), key=lambda item: -1 * item[1])}\n",
    "sort_by_val(feat_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_agg_imps = np.fromiter(feat_counts.values(), dtype=int) + np.fromiter(feat_sums.values(), dtype=float)\n",
    "args = np.argsort(relative_agg_imps)[9:] # exclude features with count of 1\n",
    "fig, ax = plt.subplots(dpi=250, figsize=(5, 3.5))\n",
    "\n",
    "\n",
    "ind = np.arange(len(args))\n",
    "reorder_for_colors = [0, 1, 3]\n",
    "width = 0.2\n",
    "\n",
    "\n",
    "cs = {\n",
    "    'Bayesian rule list': '#1f77b4',\n",
    "    'CART decision tree': '#ff7f0e',\n",
    "    'CART rule list': 'green',\n",
    "    'Iterative random forest': '#d62728',\n",
    "    'Rule fit': '#9467bd',\n",
    "    'PECARN': 'black',\n",
    "}\n",
    "colors = ['#2ca02c', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "\n",
    "for i in range(len(imps)):\n",
    "    print(viz.rename(fnames[i]))\n",
    "    ax.barh(ind - width * i, imps[i][args], width,\n",
    "            label=viz.rename(fnames[i]),\n",
    "            color=cs[viz.rename(fnames[i])]\n",
    "           )\n",
    "#     ax.barh(ind + width, df.m, width, color='green', label='M')\n",
    "\n",
    "def rename_local(x):\n",
    "        rename_map = {\n",
    "            'GCSScore_Full_yes': 'GCS Score',\n",
    "            'AbdTenderDegree_None': 'Degree of abdominal tenderness',\n",
    "            'AbdTrauma_or_SeatBeltSign_yes': 'Abdominal trauma / seatbelt sign',\n",
    "            'DecrBreathSound_yes': 'Decreased breath sounds',\n",
    "            'ThoracicTrauma_yes': 'Thoracic trauma',\n",
    "            'VomitWretch_yes': 'Vomit / wretch'\n",
    "        }\n",
    "        if x in rename_map:\n",
    "            return rename_map[x]\n",
    "        else:\n",
    "            return x.replace('_yes', '').replace('_', ' ')\n",
    "\n",
    "ax.set(yticks=ind - width - width/2,\n",
    "       yticklabels=[rename_local(lab)\n",
    "                    for lab in np.array(X.keys())[args]]) #, ylim=[2*width - 1, len(df)])\n",
    "print(X.keys()[args])\n",
    "ax.legend(frameon=False)\n",
    "plt.xlabel('Permutation importance\\n(Larger is more important)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
