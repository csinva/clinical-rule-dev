{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join as oj\n",
    "from sklearn import metrics\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from sklearn import metrics\n",
    "plt.style.use('dark_background')\n",
    "import pandas as pd\n",
    "from colorama import Fore\n",
    "import pickle as pkl\n",
    "import data, viz\n",
    "from style import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(out_dir):\n",
    "    r = []\n",
    "    for fname in os.listdir(out_dir):\n",
    "        d = pkl.load(open(oj(out_dir, fname), 'rb'))\n",
    "        metrics = {k: d['cv'][k] for k in d['cv'].keys() if not 'curve' in k}\n",
    "        out = {k: np.mean(metrics[k]) for k in metrics}\n",
    "        out.update({k + '_std': np.std(metrics[k]) for k in metrics})\n",
    "        metrics_test = {k: d['test'][k] for k in d['test'].keys() if not 'curve' in k}\n",
    "        out_test = {k + '_test': np.mean(metrics_test[k]) for k in metrics_test}\n",
    "        out_test.update({k + '_test_std': np.std(metrics_test[k]) for k in metrics_test})\n",
    "        out.update(out_test)\n",
    "        \n",
    "        \n",
    "        out['model_type'] = fname.replace('.pkl', '') #d['model_type']\n",
    "        \n",
    "        imp_mat = np.array(d['imps']['imps'])\n",
    "        imp_mu = imp_mat.mean(axis=0)\n",
    "        imp_sd = imp_mat.std(axis=0)\n",
    "        \n",
    "        feat_names = d['feat_names']\n",
    "        out.update({feat_names[i] + '_f': imp_mu[i] for i in range(len(feat_names))})\n",
    "        out.update({feat_names[i]+'_std_f': imp_sd[i] for i in range(len(feat_names))})\n",
    "        r.append(pd.Series(out))\n",
    "    r = pd.concat(r, axis=1, sort=False).T.infer_objects()\n",
    "    r = r.reindex(sorted(r.columns, reverse=True), axis=1) # sort the column names\n",
    "    r = r.round(3)\n",
    "    r = r.set_index('model_type')\n",
    "    return r\n",
    "out_dir = 'results/full_mar15_3'\n",
    "results = load_results(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**look at prediction metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prev rule: sensitivity 0.97, specificity 0.425\n",
    "r = results\n",
    "r = r[[k for k in r if not 'std' in k]]\n",
    "r = r[[k for k in r if not '_f' in k]]\n",
    "# r = r[r.index.str.contains('ros')] # only use random sampling\n",
    "# r = r.sort_values(by=['balanced_accuracy'], ascending=False)\n",
    "r = r.sort_values(by=['sensitivity', 'specificity'], ascending=False)\n",
    "\n",
    "# r.style.background_gradient(cmap='viridis', axis=None) # all values on same cmap\n",
    "\n",
    "r.style.background_gradient(cmap='viridis', axis=0) # columns differently colored\n",
    "# r.style.apply(viz.highlight_max, subset=[k for k in r if not 'std' in k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**look at feat importances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = results\n",
    "print(r.keys())\n",
    "# r.style.apply(viz.highlight_max, subset=[k for k in r if not 'std' in k])\n",
    "r = r.sort_values('balanced_accuracy', ascending=False)\n",
    "keys = [k for k in r if '_f' in k]\n",
    "keys_remapped = {k: k.replace('_f', '') for k in keys}\n",
    "r = r[keys].rename(columns=keys_remapped)\n",
    "# r = r.sort_values('lifetime')\n",
    "# r = r[r.index.str.contains('35')]\n",
    "# r = r[r.index.str.contains('11')]\n",
    "# r = r.rename(columns={'mean_square_displacement': 'msd', 'total_displacement': 'td'})\n",
    "\n",
    "r = r[r.index.str.contains('20')]\n",
    "r = r[r.index.str.contains('logistic')]\n",
    "r = r[[k for k in r if not 'std' in k]]\n",
    "\n",
    "\n",
    "def rank(r):\n",
    "    '''Rank feature importances appropriately\n",
    "    '''\n",
    "    r = r.abs()\n",
    "    r = r.rank(axis=1, ascending=False, method='min')\n",
    "    return r\n",
    "# \n",
    "# r = rank(r)\n",
    "r = r.reindex(r.mean().sort_values(ascending=True).index, axis=1) # sort cols by mean rank\n",
    "idxs = r.index\n",
    "r.insert(0, 'balanced_acc', results.loc[idxs]['balanced_accuracy'])\n",
    "r = r.sort_values('balanced_acc', ascending=False)\n",
    "subset = list(r.keys())\n",
    "subset.remove('balanced_acc')\n",
    "# r.to_html('table.html')\n",
    "# r = r.fillna(0).style.background_gradient(cmap='viridis_r', axis=1) #, subset=subset) # rows differently colored\n",
    "\n",
    "\n",
    "r = r.transpose()\n",
    "r = r.reindex(r[\"logistic_20_ros=1\"].abs().sort_values(ascending=False).index) # sort by abs value\n",
    "# r = r.sort_values(by='logistic_20_ros=1')\n",
    "r = r.fillna(0).style.background_gradient(cmap=cm, axis=0) #, subset=subset) # rows differently colored\n",
    "# r = background_gradient(r)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze individual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.get_data()\n",
    "outcome_def = 'iai_intervention'\n",
    "idxs_test = df.cv_fold.isin([6])\n",
    "X_test, Y_test = df[idxs_test], df[outcome_def][idxs_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'logistic_20_ros=5'\n",
    "# results = pkl.load(open('results/classify_outcome=y_consec_sig/rf_ros_11.pkl', 'rb'))\n",
    "results = pkl.load(open(f'results/outcome=iai_intervention/{model_name}.pkl', 'rb'))\n",
    "preds, preds_proba = viz.visualize_individual_results(results, X_test, Y_test, print_results=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# misc analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_common_feats(m_cv, model_type='tree'):\n",
    "    if model_type == 'tree':\n",
    "        feats_used = []\n",
    "        for i in range(len(m_cv['estimator'])):\n",
    "            m_fit = m_cv['estimator'][i]\n",
    "            feats_used += list(ks[m_fit.feature_importances_ != 0])\n",
    "    elif model_type == 'logistic':\n",
    "        feats_used = []\n",
    "        for i in range(len(m_cv['estimator'])):\n",
    "            m_fit = m_cv['estimator'][i]\n",
    "            num_feats = 5\n",
    "            # get top num_feats features with biggest bsolute weights\n",
    "            idxs = np.abs(m_fit.coef_).flatten().argsort()[-num_feats:][::-1]\n",
    "            feats_used += list(ks[idxs])\n",
    "    return sorted(dict(Counter(feats_used)).items(), key=lambda kv: kv[1], reverse=True)\n",
    "        \n",
    "count_common_feats(m_cv, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a tree\n",
    "m_fit = m_cv['estimator'][0]\n",
    "plt.figure(dpi=300)\n",
    "plot_tree(m_fit, feature_names=ks)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
