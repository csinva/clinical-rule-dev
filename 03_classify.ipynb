{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from os.path import join as oj\n",
    "import sys, time\n",
    "sys.path.insert(1, oj(sys.path[0], '..'))  # insert parent path\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import pickle as pkl\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit, train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "import eli5\n",
    "import pandas as pd\n",
    "import data \n",
    "from collections import Counter\n",
    "import train\n",
    "plt.style.use('dark_background')\n",
    "# sns.set(style=\"white\")\n",
    "NUM_PATIENTS = 12044\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:02<00:00, 19.22it/s]\n",
      "48it [00:07,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final shape (12044, 433)\n"
     ]
    }
   ],
   "source": [
    "# prep the dataframe\n",
    "df = data.get_features() # uses several forms\n",
    "df = data.rename_values(df) # rename features based on their meaning\n",
    "df = data.preprocess(df) # preprocess the feats\n",
    "\n",
    "# convert feats to dummy\n",
    "df = pd.get_dummies(df, dummy_na=True) # treat na as a separate category\n",
    "df = data.remove_zero_cols(df) # remove any cols that are all zero\n",
    "\n",
    "outcomes = data.get_outcomes() # 2 outcomes: iai, and iai_intervention\n",
    "df = pd.merge(df, outcomes, on='id', how='left')\n",
    "\n",
    "\n",
    "# set up train / test\n",
    "np.random.seed(42)\n",
    "df['cv_fold'] = np.random.randint(1, 7, size=df.shape[0]) # 6 is the test set\n",
    "\n",
    "# feats / outcome keys\n",
    "feat_names = [k for k in df.keys() if not k in ['id', 'cv_fold'] and not 'IAI' in k]\n",
    "outcome_def = 'iai_intervention'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX_feats = pd.get_dummies(df_filt[keys], dummy_na=True) # treat na as a separate category\\nX_feats = remove_zero_cols(X_feats)\\n    \\ndf = df[feat_names+ [outcome_def]].replace('True', 1).replace('False', 0)\\ndf = df.replace('nan', -1)\\ndf = df.fillna(-1)\\ndf = df.infer_objects()\\ndf = df.astype(float).astype(int)\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X_feats = pd.get_dummies(df_filt[keys], dummy_na=True) # treat na as a separate category\n",
    "X_feats = remove_zero_cols(X_feats)\n",
    "    \n",
    "df = df[feat_names+ [outcome_def]].replace('True', 1).replace('False', 0)\n",
    "df = df.replace('nan', -1)\n",
    "df = df.fillna(-1)\n",
    "df = df.infer_objects()\n",
    "df = df.astype(float).astype(int)\n",
    "'''\n",
    "\n",
    "# remove unusable features\n",
    "# X_feats_full= X_feats_full[ks]\n",
    "\n",
    "# get actual features\n",
    "# X_np = X_feats_full.values\n",
    "\n",
    "# y_np = outcomes['iai_intervention']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'ageinyrs', 'EDTriageTime_1', 'InjuryDay_1', 'InjTmKnown_1',\n",
       "       'TriageTmUnkown_1', 'Certification_1', 'LtCostalTender_1',\n",
       "       'RtCostalTender_1', 'AbnChestAusc_1',\n",
       "       ...\n",
       "       'AbdTenderDegree_1_2.0', 'AbdTenderDegree_1_3.0',\n",
       "       'AbdTenderDegree_1_4.0', 'AbdTenderDegree_1_nan', 'Costal_1_True',\n",
       "       'AbdTrauma_or_SeatBeltSign_1_False', 'AbdTrauma_or_SeatBeltSign_1_True',\n",
       "       'iai', 'iai_intervention', 'cv_fold'],\n",
       "      dtype='object', length=115)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pecarn_feats(feat_names):\n",
    "    '''Get dummy variable names\n",
    "    '''\n",
    "    pecarn_feats = ['VomitWretch_1', 'RecodedMOI_1', 'GCSScore_1', 'ThoracicTender_1', 'ThoracicTrauma_1', \n",
    "              'Cosatsl_1', 'DecrBreathSound_1', 'AbdDistention_1', 'AbdomenPain_1', 'AbdTenderDegree_1',\n",
    "              'AbdTrauma_1', 'SeatBeltSign_1', 'DistractingPain_1']\n",
    "    # InjuryMechanism_1, hypotension?, femure fracture\n",
    "    ks = set()\n",
    "    for pecarn_feat in pecarn_feats:\n",
    "        for feat_name in feat_names:\n",
    "            if pecarn_feat in feat_name:\n",
    "                ks.add(feat_name)\n",
    "    ks = np.array(list(ks))\n",
    "    return ks\n",
    "pecarn_feats = get_pecarn_feats(feat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [01:03<05:15, 63.02s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [01:07<03:01, 45.38s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [01:09<01:37, 32.38s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [31:20<18:52, 566.04s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [31:47<06:44, 404.24s/it]\u001b[A/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "\n",
      "100%|██████████| 6/6 [36:08<00:00, 361.35s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "for balancing in ['ros']:\n",
    "    for model_type in tqdm(['gb', 'logistic', 'dt', 'svm', 'rf', 'mlp2']):\n",
    "        for num_feats in [5, 10, 20, 30, 52]: #111]:\n",
    "            # feats = feat_names[:num_feats]\n",
    "            feats = pecarn_feats[:num_feats]\n",
    "            out_dir = f'results/outcome={outcome_def}'\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "            out_name = f'{model_type}_{len(feats)}_{balancing}'\n",
    "            train.train(df, feat_names=feats, model_type=model_type, balancing=balancing, outcome_def=outcome_def,\n",
    "                        out_name=f'{out_dir}/{out_name}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
